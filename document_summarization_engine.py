# -*- coding: utf-8 -*-
"""Document Summarization Engine

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CAQI0Uf8Et5-Pg2jBlF8O0-fH9z0ZZO9
"""

!pip install pymupdf sumy transformers torch sentencepiece ipywidgets
!pip install -U langchain-community

import nltk
nltk.download('punkt_tab')

import fitz  # pymupdf
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.text_rank import TextRankSummarizer
from transformers import pipeline
import os
import nltk
nltk.download('punkt')
from nltk.tokenize import sent_tokenize

# For file upload in notebook
try:
    from google.colab import files
    COLAB = True
except ImportError:
    COLAB = False
from IPython.display import display
if not COLAB:
    import ipywidgets as widgets

def upload_file():
    if COLAB:
        print("Upload your PDF or TXT file:")
        uploaded = files.upload()
        filename = list(uploaded.keys())[0]
        print(f"Uploaded file: {filename}")
        return filename
    else:
        print("Upload your PDF or TXT file:")
        uploader = widgets.FileUpload(accept='.pdf,.txt', multiple=False)
        display(uploader)
        while not uploader.value:
            pass
        for filename in uploader.value:
            content = uploader.value[filename]['content']
            with open(filename, 'wb') as f:
                f.write(content)
            print(f"Uploaded file: {filename}")
            return filename

def load_pdf(file_path):
    doc = fitz.open(file_path)
    full_text = ""
    for page in doc:
        full_text += page.get_text()
    return full_text

def load_text_file(file_path):
    with open(file_path, "r", encoding="utf-8") as f:
        return f.read()

def extractive_summary(text, sentences_count=5):
    parser = PlaintextParser.from_string(text, Tokenizer("english"))
    summarizer = TextRankSummarizer()
    summary = summarizer(parser.document, sentences_count)
    summarized_text = "\n- " + "\n- ".join(str(sentence) for sentence in summary)
    return summarized_text

def chunk_text_by_sentences(text, max_words=150):
    sentences = sent_tokenize(text)
    chunks = []
    chunk = []
    count = 0
    for sent in sentences:
        words = len(sent.split())
        if count + words > max_words and chunk:
            chunks.append(" ".join(chunk))
            chunk = [sent]
            count = words
        else:
            chunk.append(sent)
            count += words
    if chunk:
        chunks.append(" ".join(chunk))
    return chunks

def abstractive_summary(text, max_length=150, min_length=40):
    summarizer = pipeline("summarization", model="facebook/bart-large-cnn")
    text_chunks = chunk_text_by_sentences(text)
    summaries = []
    for chunk in text_chunks:
        summary = summarizer(chunk, max_length=max_length, min_length=min_length, do_sample=False)
        summaries.append(summary[0]['summary_text'])
    return " ".join(summaries)

def save_summary_to_file(text, filename="summary.md"):
    with open(filename, "w", encoding="utf-8") as f:
        f.write(text)
    print(f"✅ Summary saved to: {filename}")

def main():
    filename = upload_file()
    ext = os.path.splitext(filename)[1].lower()

    if ext == ".pdf":
        print("Loading PDF...")
        text = load_pdf(filename)
    elif ext == ".txt":
        print("Loading text file...")
        text = load_text_file(filename)
    else:
        print("Unsupported file format! Please upload PDF or TXT.")
        return

    print("\n=== Extractive Summary (TextRank) ===\n")
    extractive = extractive_summary(text)
    print(extractive)

    print("\n=== Abstractive Summary (BART) ===\n")
    abstractive = abstractive_summary(text)
    print(abstractive)

    base_name = os.path.splitext(os.path.basename(filename))[0].replace(" ", "_")
    extractive_file = f"{base_name}_extractive_summary.md"
    abstractive_file = f"{base_name}_abstractive_summary.md"

    save_summary_to_file(extractive, filename=extractive_file)
    save_summary_to_file(abstractive, filename=abstractive_file)

    print("\n✅ Summaries saved successfully!")

if __name__ == "__main__":
    main()